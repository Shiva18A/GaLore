{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from galore_torch import GaLoreAdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification, AutoConfig, TrainingArguments, Trainer\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification, AutoConfig, TrainingArguments, Trainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                    \n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)), \n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "from datasets import Dataset\n",
    "def convert_to_hf_dataset(pytorch_dataset):\n",
    "    \n",
    "    images = [data[0].numpy() for data in pytorch_dataset]\n",
    "    labels = [data[1] for data in pytorch_dataset]\n",
    "    return Dataset.from_dict({\"pixel_values\": images, \"labels\": labels})\n",
    "\n",
    "hf_train_dataset = convert_to_hf_dataset(train_dataset)\n",
    "hf_test_dataset = convert_to_hf_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTConfig, ViTForImageClassification\n",
    "#from torchsummary import summary\n",
    "import torch\n",
    "\n",
    "config = ViTConfig(\n",
    "    image_size=32,           \n",
    "    patch_size=4,            \n",
    "    num_channels=3,          \n",
    "    hidden_size=384,         \n",
    "    num_hidden_layers=7,     \n",
    "    num_attention_heads=12,   \n",
    "    intermediate_size=384,  \n",
    "    num_labels=10           \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 384, kernel_size=(4, 4), stride=(4, 4))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-6): 7 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=384, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ViTForImageClassification(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",           \n",
    "    evaluation_strategy=\"epoch\",           \n",
    "    save_strategy=\"no\",              \n",
    "    learning_rate=5e-4,              \n",
    "    per_device_train_batch_size=512,  \n",
    "    per_device_eval_batch_size=512,   \n",
    "    num_train_epochs=5,              \n",
    "    weight_decay=0.01,               \n",
    "    logging_dir=\"./logs\",            \n",
    "    logging_steps=10,                \n",
    "    remove_unused_columns=True,      \n",
    "    report_to=\"none\",                \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/Galore/galore_torch/adamw.py:49: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_parameters = list(model.named_parameters())\n",
    "\n",
    "galore_params = []\n",
    "non_galore_params = []\n",
    "\n",
    "for name, param in model_parameters:\n",
    "    if (\"attention\" in name or \"intermediate\" in name) and param.ndim == 2:\n",
    "        galore_params.append(param)\n",
    "    else:\n",
    "        non_galore_params.append(param)\n",
    "\n",
    "param_groups = [\n",
    "    {'params': non_galore_params},  \n",
    "    {\n",
    "        'params': galore_params,\n",
    "        'rank': 64,  \n",
    "        'update_proj_gap': 50,\n",
    "        'scale': 0.10,\n",
    "        'proj_type': 'std',  \n",
    "    },\n",
    "]\n",
    "\n",
    "optimizer = GaLoreAdamW(param_groups, lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == eval_pred.label_ids).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_train_dataset,\n",
    "    eval_dataset=hf_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, None),\n",
    "    callbacks=[InlineProfilerCallback()],  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='686' max='686' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [686/686 20:13, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.802100</td>\n",
       "      <td>1.761530</td>\n",
       "      <td>0.360500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.581900</td>\n",
       "      <td>1.568274</td>\n",
       "      <td>0.419700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.488600</td>\n",
       "      <td>1.487626</td>\n",
       "      <td>0.448400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.377400</td>\n",
       "      <td>1.379276</td>\n",
       "      <td>0.495400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.320900</td>\n",
       "      <td>1.321116</td>\n",
       "      <td>0.521700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.227800</td>\n",
       "      <td>1.269860</td>\n",
       "      <td>0.536700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.211600</td>\n",
       "      <td>1.237881</td>\n",
       "      <td>0.552200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed in 151.27 seconds\n",
      "Peak GPU memory usage: 4.646 GB\n",
      "Current GPU memory usage: 0.174 GB\n",
      "Cached GPU memory: 5.088 GB\n",
      "Epoch 2 completed in 149.92 seconds\n",
      "Peak GPU memory usage: 4.646 GB\n",
      "Current GPU memory usage: 0.174 GB\n",
      "Cached GPU memory: 5.088 GB\n",
      "Epoch 3 completed in 149.25 seconds\n",
      "Peak GPU memory usage: 4.646 GB\n",
      "Current GPU memory usage: 0.174 GB\n",
      "Cached GPU memory: 5.088 GB\n",
      "Epoch 4 completed in 150.11 seconds\n",
      "Peak GPU memory usage: 4.646 GB\n",
      "Current GPU memory usage: 0.174 GB\n",
      "Cached GPU memory: 5.088 GB\n",
      "Epoch 5 completed in 150.69 seconds\n",
      "Peak GPU memory usage: 4.646 GB\n",
      "Current GPU memory usage: 0.174 GB\n",
      "Cached GPU memory: 5.088 GB\n",
      "Epoch 6 completed in 151.10 seconds\n",
      "Peak GPU memory usage: 4.646 GB\n",
      "Current GPU memory usage: 0.174 GB\n",
      "Cached GPU memory: 5.088 GB\n",
      "Epoch 7 completed in 149.86 seconds\n",
      "Peak GPU memory usage: 4.646 GB\n",
      "Current GPU memory usage: 0.174 GB\n",
      "Cached GPU memory: 5.088 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=686, training_loss=1.473583958239319, metrics={'train_runtime': 1216.3378, 'train_samples_per_second': 287.749, 'train_steps_per_second': 0.564, 'total_flos': 4.0441347072e+16, 'train_loss': 1.473583958239319, 'epoch': 7.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class InlineProfilerCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        self.epoch_start_time = time.time()  \n",
    "        torch.cuda.reset_peak_memory_stats()  \n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        epoch_time = time.time() - self.epoch_start_time  \n",
    "        peak_memory = torch.cuda.max_memory_allocated() / 1e9  \n",
    "        current_memory = torch.cuda.memory_allocated() / 1e9   \n",
    "        cached_memory = torch.cuda.memory_reserved() / 1e9    \n",
    "\n",
    "        current_epoch = int(state.epoch)\n",
    "        print(f\"Epoch {current_epoch} completed in {epoch_time:.2f} seconds\")\n",
    "        print(f\"Peak GPU memory usage: {peak_memory:.3f} GB\")\n",
    "        print(f\"Current GPU memory usage: {current_memory:.3f} GB\")\n",
    "        print(f\"Cached GPU memory: {cached_memory:.3f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# randomized svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/Galore/galore_torch/adamw.py:49: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_parameters = list(model.named_parameters())\n",
    "\n",
    "\n",
    "galore_params = []\n",
    "non_galore_params = []\n",
    "\n",
    "for name, param in model_parameters:\n",
    "    if (\"attention\" in name or \"intermediate\" in name) and param.ndim == 2:\n",
    "        galore_params.append(param)\n",
    "    else:\n",
    "        non_galore_params.append(param)\n",
    "\n",
    "param_groups = [\n",
    "    {\n",
    "        'params': non_galore_params\n",
    "    },\n",
    "    {\n",
    "        'params': galore_params,\n",
    "        'rank': 64,\n",
    "        'update_proj_gap': 100,\n",
    "        'scale': 0.25,\n",
    "        'proj_type': 'std',\n",
    "        'use_randomized_svd': True  # Enable randomized SVD\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = GaLoreAdamW(param_groups, lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == eval_pred.label_ids).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_train_dataset,\n",
    "    eval_dataset=hf_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, None),\n",
    "    callbacks=[InlineProfilerCallback()],  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='686' max='686' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [686/686 20:03, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.779000</td>\n",
       "      <td>1.714048</td>\n",
       "      <td>0.369900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.510100</td>\n",
       "      <td>1.495061</td>\n",
       "      <td>0.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.360300</td>\n",
       "      <td>1.380858</td>\n",
       "      <td>0.498900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.277600</td>\n",
       "      <td>1.293311</td>\n",
       "      <td>0.532300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.219600</td>\n",
       "      <td>1.222517</td>\n",
       "      <td>0.556000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.125900</td>\n",
       "      <td>1.173395</td>\n",
       "      <td>0.579800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.102300</td>\n",
       "      <td>1.148384</td>\n",
       "      <td>0.593100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed in 151.40 seconds\n",
      "Peak GPU memory usage: 4.538 GB\n",
      "Current GPU memory usage: 0.066 GB\n",
      "Cached GPU memory: 4.918 GB\n",
      "Epoch 2 completed in 148.79 seconds\n",
      "Peak GPU memory usage: 4.538 GB\n",
      "Current GPU memory usage: 0.066 GB\n",
      "Cached GPU memory: 4.918 GB\n",
      "Epoch 3 completed in 148.07 seconds\n",
      "Peak GPU memory usage: 4.538 GB\n",
      "Current GPU memory usage: 0.066 GB\n",
      "Cached GPU memory: 4.918 GB\n",
      "Epoch 4 completed in 148.45 seconds\n",
      "Peak GPU memory usage: 4.538 GB\n",
      "Current GPU memory usage: 0.066 GB\n",
      "Cached GPU memory: 4.918 GB\n",
      "Epoch 5 completed in 148.76 seconds\n",
      "Peak GPU memory usage: 4.538 GB\n",
      "Current GPU memory usage: 0.066 GB\n",
      "Cached GPU memory: 4.920 GB\n",
      "Epoch 6 completed in 147.76 seconds\n",
      "Peak GPU memory usage: 4.538 GB\n",
      "Current GPU memory usage: 0.066 GB\n",
      "Cached GPU memory: 4.920 GB\n",
      "Epoch 7 completed in 148.43 seconds\n",
      "Peak GPU memory usage: 4.538 GB\n",
      "Current GPU memory usage: 0.066 GB\n",
      "Cached GPU memory: 4.920 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=686, training_loss=1.3875788662245947, metrics={'train_runtime': 1206.6163, 'train_samples_per_second': 290.067, 'train_steps_per_second': 0.569, 'total_flos': 4.0441347072e+16, 'train_loss': 1.3875788662245947, 'epoch': 7.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normal svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/Galore/galore_torch/adamw.py:49: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_parameters = list(model.named_parameters())\n",
    "\n",
    "\n",
    "galore_params = []\n",
    "non_galore_params = []\n",
    "\n",
    "for name, param in model_parameters:\n",
    "    if (\"attention\" in name or \"intermediate\" in name) and param.ndim == 2:\n",
    "        galore_params.append(param)\n",
    "    else:\n",
    "        non_galore_params.append(param)\n",
    "\n",
    "param_groups = [\n",
    "    {\n",
    "        'params': non_galore_params\n",
    "    },\n",
    "    {\n",
    "        'params': galore_params,\n",
    "        'rank': 64,\n",
    "        'update_proj_gap': 100,\n",
    "        'scale': 0.25,\n",
    "        'proj_type': 'std',\n",
    "        'use_randomized_svd': False  # Enable randomized SVD\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = GaLoreAdamW(param_groups, lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == eval_pred.label_ids).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_train_dataset,\n",
    "    eval_dataset=hf_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, None),\n",
    "    callbacks=[InlineProfilerCallback()],  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='686' max='686' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [686/686 20:07, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.772200</td>\n",
       "      <td>1.706230</td>\n",
       "      <td>0.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.520700</td>\n",
       "      <td>1.527251</td>\n",
       "      <td>0.440200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.367800</td>\n",
       "      <td>1.363507</td>\n",
       "      <td>0.504400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.278900</td>\n",
       "      <td>1.283744</td>\n",
       "      <td>0.527500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.213600</td>\n",
       "      <td>1.245465</td>\n",
       "      <td>0.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.138000</td>\n",
       "      <td>1.201433</td>\n",
       "      <td>0.562700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.113700</td>\n",
       "      <td>1.166211</td>\n",
       "      <td>0.578400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed in 149.34 seconds\n",
      "Peak GPU memory usage: 4.605 GB\n",
      "Current GPU memory usage: 0.133 GB\n",
      "Cached GPU memory: 5.050 GB\n",
      "Epoch 2 completed in 149.81 seconds\n",
      "Peak GPU memory usage: 4.605 GB\n",
      "Current GPU memory usage: 0.133 GB\n",
      "Cached GPU memory: 5.050 GB\n",
      "Epoch 3 completed in 149.17 seconds\n",
      "Peak GPU memory usage: 4.605 GB\n",
      "Current GPU memory usage: 0.133 GB\n",
      "Cached GPU memory: 5.050 GB\n",
      "Epoch 4 completed in 149.21 seconds\n",
      "Peak GPU memory usage: 4.605 GB\n",
      "Current GPU memory usage: 0.133 GB\n",
      "Cached GPU memory: 5.050 GB\n",
      "Epoch 5 completed in 149.28 seconds\n",
      "Peak GPU memory usage: 4.605 GB\n",
      "Current GPU memory usage: 0.133 GB\n",
      "Cached GPU memory: 5.050 GB\n",
      "Epoch 6 completed in 149.41 seconds\n",
      "Peak GPU memory usage: 4.605 GB\n",
      "Current GPU memory usage: 0.133 GB\n",
      "Cached GPU memory: 5.050 GB\n",
      "Epoch 7 completed in 149.23 seconds\n",
      "Peak GPU memory usage: 4.605 GB\n",
      "Current GPU memory usage: 0.133 GB\n",
      "Cached GPU memory: 5.050 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=686, training_loss=1.3912460901299302, metrics={'train_runtime': 1210.6872, 'train_samples_per_second': 289.092, 'train_steps_per_second': 0.567, 'total_flos': 4.0441347072e+16, 'train_loss': 1.3912460901299302, 'epoch': 7.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 384, kernel_size=(4, 4), stride=(4, 4))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-6): 7 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=384, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ViTForImageClassification(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",           \n",
    "    evaluation_strategy=\"epoch\",           \n",
    "    save_strategy=\"no\",              \n",
    "    learning_rate=5e-4,              \n",
    "    per_device_train_batch_size=512,  \n",
    "    per_device_eval_batch_size=512,   \n",
    "    num_train_epochs=5,              \n",
    "    weight_decay=0.01,               \n",
    "    logging_dir=\"./logs\",            \n",
    "    logging_steps=10,                \n",
    "    remove_unused_columns=True,      \n",
    "    report_to=\"none\",                \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/Galore/galore_torch/adamw.py:49: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_parameters = list(model.named_parameters())\n",
    "\n",
    "galore_params = []\n",
    "non_galore_params = []\n",
    "\n",
    "for name, param in model_parameters:\n",
    "    if (\"attention\" in name or \"intermediate\" in name) and param.ndim == 2:\n",
    "        galore_params.append(param)\n",
    "    else:\n",
    "        non_galore_params.append(param)\n",
    "\n",
    "param_groups = [\n",
    "    {\n",
    "        'params': non_galore_params\n",
    "    },\n",
    "    {\n",
    "        'params': galore_params,\n",
    "        'rank': 128,\n",
    "        'update_proj_gap': 10,\n",
    "        'scale': 0.25,\n",
    "        'proj_type': 'std',\n",
    "        'use_randomized_svd': True  # Enable randomized SVD\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = GaLoreAdamW(param_groups, lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == eval_pred.label_ids).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_train_dataset,\n",
    "    eval_dataset=hf_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, None),\n",
    "    callbacks=[InlineProfilerCallback()],  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 14:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.772200</td>\n",
       "      <td>1.693816</td>\n",
       "      <td>0.377400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.534400</td>\n",
       "      <td>1.539204</td>\n",
       "      <td>0.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.412800</td>\n",
       "      <td>1.417106</td>\n",
       "      <td>0.485400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.326100</td>\n",
       "      <td>1.333881</td>\n",
       "      <td>0.514200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.285100</td>\n",
       "      <td>1.294585</td>\n",
       "      <td>0.530800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed in 150.15 seconds\n",
      "Peak GPU memory usage: 4.548 GB\n",
      "Current GPU memory usage: 0.076 GB\n",
      "Cached GPU memory: 4.933 GB\n",
      "Epoch 2 completed in 148.51 seconds\n",
      "Peak GPU memory usage: 4.548 GB\n",
      "Current GPU memory usage: 0.076 GB\n",
      "Cached GPU memory: 4.935 GB\n",
      "Epoch 3 completed in 147.00 seconds\n",
      "Peak GPU memory usage: 4.548 GB\n",
      "Current GPU memory usage: 0.076 GB\n",
      "Cached GPU memory: 4.935 GB\n",
      "Epoch 4 completed in 147.57 seconds\n",
      "Peak GPU memory usage: 4.548 GB\n",
      "Current GPU memory usage: 0.076 GB\n",
      "Cached GPU memory: 4.935 GB\n",
      "Epoch 5 completed in 146.99 seconds\n",
      "Peak GPU memory usage: 4.548 GB\n",
      "Current GPU memory usage: 0.076 GB\n",
      "Cached GPU memory: 4.935 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=490, training_loss=1.5264379326178104, metrics={'train_runtime': 853.6893, 'train_samples_per_second': 292.847, 'train_steps_per_second': 0.574, 'total_flos': 2.888667648e+16, 'train_loss': 1.5264379326178104, 'epoch': 5.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/Galore/galore_torch/adamw.py:49: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_parameters = list(model.named_parameters())\n",
    "\n",
    "galore_params = []\n",
    "non_galore_params = []\n",
    "\n",
    "for name, param in model_parameters:\n",
    "    if (\"attention\" in name or \"intermediate\" in name) and param.ndim == 2:\n",
    "        galore_params.append(param)\n",
    "    else:\n",
    "        non_galore_params.append(param)\n",
    "\n",
    "param_groups = [\n",
    "    {\n",
    "        'params': non_galore_params\n",
    "    },\n",
    "    {\n",
    "        'params': galore_params,\n",
    "        'rank': 128,\n",
    "        'update_proj_gap': 10,\n",
    "        'scale': 0.25,\n",
    "        'proj_type': 'std',\n",
    "        'use_randomized_svd': False  # Enable randomized SVD\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = GaLoreAdamW(param_groups, lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == eval_pred.label_ids).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_train_dataset,\n",
    "    eval_dataset=hf_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, None),\n",
    "    callbacks=[InlineProfilerCallback()],  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 14:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.772400</td>\n",
       "      <td>1.731964</td>\n",
       "      <td>0.375100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.549400</td>\n",
       "      <td>1.557702</td>\n",
       "      <td>0.425500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.442300</td>\n",
       "      <td>1.430607</td>\n",
       "      <td>0.478100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.339900</td>\n",
       "      <td>1.345578</td>\n",
       "      <td>0.513900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.295400</td>\n",
       "      <td>1.300729</td>\n",
       "      <td>0.529000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed in 153.92 seconds\n",
      "Peak GPU memory usage: 4.586 GB\n",
      "Current GPU memory usage: 0.115 GB\n",
      "Cached GPU memory: 5.023 GB\n",
      "Epoch 2 completed in 153.60 seconds\n",
      "Peak GPU memory usage: 4.586 GB\n",
      "Current GPU memory usage: 0.115 GB\n",
      "Cached GPU memory: 5.023 GB\n",
      "Epoch 3 completed in 153.82 seconds\n",
      "Peak GPU memory usage: 4.586 GB\n",
      "Current GPU memory usage: 0.115 GB\n",
      "Cached GPU memory: 5.023 GB\n",
      "Epoch 4 completed in 156.22 seconds\n",
      "Peak GPU memory usage: 4.586 GB\n",
      "Current GPU memory usage: 0.115 GB\n",
      "Cached GPU memory: 5.023 GB\n",
      "Epoch 5 completed in 156.83 seconds\n",
      "Peak GPU memory usage: 4.586 GB\n",
      "Current GPU memory usage: 0.115 GB\n",
      "Cached GPU memory: 5.023 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=490, training_loss=1.5406883122969648, metrics={'train_runtime': 888.7109, 'train_samples_per_second': 281.306, 'train_steps_per_second': 0.551, 'total_flos': 2.888667648e+16, 'train_loss': 1.5406883122969648, 'epoch': 5.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
